\subsection{Unconditional Queries}
\label{uncondq}
The unconditional probability of an atom can be asked using \verb|pita| with the predicate
\begin{verbatim}
prob(:Query:atom,-Probability:float).
\end{verbatim}
as in
\begin{verbatim}
?- prob(heads(coin),P).
\end{verbatim}
If the query is non-ground, \verb|prob/2| returns in backtracking the succesful instantiations together with their probability.

When using \verb|mcintyre|, the predicate for querying is 
\begin{verbatim}
mc_prob(:Query:atom,-Probability:float).
\end{verbatim} as in
\begin{verbatim}
?- mc_prob(heads(coin),P).
\end{verbatim}
With \verb|mcintyre|, you can also take a given number of sample with
\begin{verbatim}
mc_sample(:Query:atom,+Samples:int,-Successes:int,-Failures:int,
  -Probability:float).
\end{verbatim}
as in (\href{http://cplint.lamping.unife.it/example/inference/coinmc.pl}{\texttt{coinmc.pl}})
\begin{verbatim}
?- mc_sample(heads(coin),1000,S,F,P).
\end{verbatim}
that samples \verb|heads(coin)| 1000 times and returns in \verb|S| the number of successes, in \verb|F| the number of failures and in \verb|P| the
estimated probability (\verb|S/1000|).

Differently from exact inference, in approximate inference the query can be a conjunction of atoms.

If you are just interested in the probability, you can use
\begin{verbatim}
mc_sample(:Query:atom,+Samples:int,-Probability:float) 
\end{verbatim}
as in (\href{http://cplint.lamping.unife.it/example/inference/coinmc.pl}{\texttt{coinmc.pl}})
\begin{verbatim}
?- mc_sample(heads(coin),1000,Prob).
\end{verbatim}
that samples \verb|heads(coin)| 1000 times and returns the
estimated probability that a sample is true (i.e., that a sample succeeds).


Moreover, you can sample arguments of queries with
\begin{verbatim}
mc_sample_arg(:Query:atom,+Samples:int,?Arg:var,-Values:list).
\end{verbatim}
The predicate samples \verb|Query| a number of \verb|Samples| times. 
\verb|Arg| should be a variable in \verb|Query|.
The predicate returns in \verb|Values| a list of couples \verb|L-N| where
\verb|L| is the list of values of \verb|Arg| for which \verb|Query|
succeeds in a world sampled at random and \verb|N|
is the number of samples returning that list of values.
If \verb|L| is the empty list, it means that for that
sample the query failed. 
If \verb|L| is a list with a 
single element, it means that for that sample the query is 
determinate. 
If, in all couples \verb|L-N|, \verb|L| 
is a list with a 
single element, it means that the clauses in the program 
are mutually exclusive, i.e., that in every sample, only
one clause for each subgoal has the body true. This is one
of the assumptions taken for programs of the PRISM system \cite{DBLP:journals/jair/SatoK01}.
For example
\href{http://cplint.lamping.unife.it/example/inference/pfcglr.pl}{\texttt{pfcglr.pl}} and \href{http://cplint.lamping.unife.it/example/inference/plcg.pl}{\texttt{plcg.pl}} satisfy this constraint while
 \href{http://cplint.lamping.unife.it/example/inference/markov_chain.pl}{\texttt{markov\_chain.pl}} and \href{http://cplint.lamping.unife.it/example/inference/var_obj.pl}{\texttt{var\_obj.pl}} don't.


An example of use of the above predicate is
\begin{verbatim}
?- mc_sample_arg(reach(s0,0,S),50,S,Values). 
\end{verbatim}
of \href{http://cplint.lamping.unife.it/example/inference/markov_chain.pl}{\texttt{markov\_chain.pl}}
that takes 50 samples of \verb|L| in \verb|findall(S,(reach(s0,0,S),L)|.

You can sample arguments of queries also with
\begin{verbatim}
mc_sample_arg_first(:Query:atom,+Samples:int,?Arg:var,-Values:list).
\end{verbatim}
samples \verb|Query| a number of \verb|Samples| times 
and returns in \verb|Values| a list of couples \verb|V-N| where 
\verb|V| is the value of \verb|Arg| returned as the first answer by \verb|Query| in 
a world sampled at random and \verb|N| is the number of samples
returning that value.
\verb|V| is failure if the query fails.
\verb|mc_sample_arg_first/4| differs from \verb|mc_sample_arg/4| because the first just computes the first
answer of the query for each sampled world.

%Alternatively, you can use
%\begin{verbatim}
%mc_sample_arg_one(:Query:atom,+Samples:int,?Arg:var,-Values:list)
%\end{verbatim}
%that samples \verb|Query| a number of \verb|Samples| times 
%and returns in \verb|Values| a list of couples \verb|V-N| where 
%\verb|V| is a value sampled with uniform probability from those returned 
%by \verb|Query| in a world sampled at random and \verb|N| is the number of samples
%returning that value.
%\verb|V| is failure if the query fails.

Finally, you can compute expectations with 
\begin{verbatim}
mc_expectation(:Query:atom,+N:int,?Arg:var,-Exp:float).
\end{verbatim}
that computes the expected value of \verb|Arg| in \verb|Query| by
sampling.
It takes \verb|N| samples of \verb|Query| and sums up the value of \verb|Arg| for
each sample. The overall sum is divided by \verb|N| to give \verb|Exp|.

An example of use of the above predicate is
\begin{verbatim}
?- mc_expectation(eventually(elect,T),1000,T,E).
\end{verbatim}
of \href{http://cplint.lamping.unife.it/example/inference/pctl_slep.pl}{\texttt{pctl\_slep.pl}}
that returns in \verb|E| the expected value of \verb|T| by taking 1000 samples.

\subsubsection{Drawing BDDs}

With \verb|pita|, you can obtain the BDD for a query with the predicates
\begin{verbatim}
bdd_dot_file(:Query:atom,+FileName:string,-Var:list)
bdd_dot_string(:Query:atom,-DotString:string,-Var:list)
\end{verbatim}
The first write the BDD to a file, the latter returns it as a string.
The BDD is represented in the dot format of graphviz.
Solid edges indicate 1-children, dashed edges indicate 0-children and dotted
edges indicate 0-children with negation applied to the sub BDD.
Each level of the BDD is associated to a variable of the form XI\_J indicated on the left:
I indicates the rule index and J the index of the Boolean variable of rule I.
The hexadecimal number in each node is part of its address in memory and is not significant.
The table \verb|Var| contains the associations between the rule groundings and the
multivalued variables: the first column contains the rule index, corresponding
to its position in the program, the second column contains the list 
of constants grounding the rule, each replacing a variable in the order of appearance in the
rule, and the last column contains the multivalued variable index.

The BDD can be drawn in \verb|cplint| on SWISH by using the \verb|graphviz| renderer.


\subsection{Conditional Queries on Discrete Variables}
\label{condq}
The conditional probability of an atom query given another atom evidence can be asked using \verb|pita| with the predicate 
\begin{verbatim}
prob(:Query:atom,:Evidence:atom,-Probability:float).
\end{verbatim}
as in
\begin{verbatim}
?- prob(heads(coin),biased(coin),P).
\end{verbatim}
If the query/evidence are non-ground, \verb|prob/3| returns in backtracking ground instantiations together with their probability.

If the evidence is composed of more than one atom, a clause of the form
\begin{verbatim}
evidence:- e1,...,en.
\end{verbatim}
should be added to the program, where \verb|e1,...,en| are the evidence atoms, and the query \verb|prob(goal,evidence,P).| should be asked.


When using \verb|mcintyre|, you can ask conditional queries with rejection sampling or with Metropolis-Hastings Markov Chain Monte Carlo.
In rejection sampling \cite{von195113}, you first query the evidence and, if the query is successful, query the goal in the same sample, otherwise
the sample is discarded.
In Metropolis-Hastings MCMC, \verb|mcintyre| follows the algorithm proposed in \cite{nampally2014adaptive} (the non adaptive version).
A Markov chain is built by building an initial sample and by generating successor samples.

The initial sample is built by  randomly sampling choices so that the evidence is true. This is done with
a backtracking meta-interpreter that starts with the goal and
randomizes the order in which clauses are selected during the search so that the initial sample is unbiased. Each time the meta-interpreter encounters 
a probabilistic choice, it first checks whether a
value has already been sampled, if not, it takes
a sample and records it. If a failure is obtained,
the meta-interpreter backtracks to other clauses but
without deleting samples. Then the goal is queries using 
regular MCINTYRE.

A successor sample is obtained by deleting a 
fixed number (parameter \verb|Lag|) of sampled probabilistic choices. Then the
evidence is queried using regular MCINTYRE starting with the undeleted choices.
If the query succeeds, the goal is queried using regular MCINTYRE.
The sample is accepted with a probability of $\min\{1,\frac{N_0}{N_1}\}$ where $N_0$ is the number of choices sampled
in the previous sample and $N_1$ is the number of choices sampled in the current sample.
In \cite{nampally2014adaptive} the lag is always 1 but the proof in \cite{nampally2014adaptive} that the above acceptance
probability yields a valid
Metropolis-Hastings algorithm holds also when forgetting more than one 
sampled choice, so the lag is 
user defined in \verb|cplint|.

Then the number of successes of the query is increased by 1 if the query succeeded in the last accepted
sample. The final probability is given by the number of successes over the total 
number of samples.

You can take a given number of sample with rejection sampling using
\begin{verbatim}
mc_rejection_sample(:Query:atom,:Evidence:atom,+Samples:int,
  -Successes:int,-Failures:int,-Probability:float).
\end{verbatim}
as in (\href{http://cplint.lamping.unife.it/example/inference/coinmc.pl}{\texttt{coinmc.pl}})
\begin{verbatim}
?- mc_rejection_sample(heads(coin),biased(coin),1000,S,F,P).
\end{verbatim}
that takes 1000 samples where \verb|biased(coin)| is true and returns in \verb|S| the number of samples where 
\verb|heads(coin)| is true, in \verb|F| the number of samples where \verb|heads(coin)| is false and in \verb|P| the
estimated probability (\verb|S/1000|).

Differently from exact inference, in approximate inference the evidence can be a conjunction of atoms.

You can take a given number of sample with Metropolis-Hastings MCMC using
\begin{verbatim}
mc_mh_sample(:Query:atom,:Evidence:atom,+Samples:int,+Lag:int,
  -Successes:int,-Failures:int,-Probability:float).
\end{verbatim}
where \verb|Lag| is the number of sampled choices to forget before taking a new sample.
For example (\href{http://cplint.lamping.unife.it/example/inference/arithm.pl}{\texttt{arithm.pl}})
\begin{verbatim}
?- mc_mh_sample(eval(2,4),eval(1,3),10000,1,T,F,P).
\end{verbatim}
takes 10000 accepted samples and returns in \verb|T| the number of samples where 
\verb|eval(2,4)| is true, in \verb|F| the number of samples where \verb|eval(2,4)| is false and in \verb|P| the
estimated probability (\verb|T/10000|).

You can allow for mixing time with
\begin{verbatim}
mc_mh_sample(:Query:atom,:Evidence:atom,+Samples:int,+Mix:int,+Lag:int,
  -Successes:int,-Failures:int,-Probability:float).
\end{verbatim}
that takes \verb|Mix+Samples| samples and discards the first \verb|Mix|.


Moreover, you can sample arguments of queries with rejection sampling and Metropolis-Hastings MCMC using
\begin{verbatim}
mc_rejection_sample_arg(:Query:atom,:Evidence:atom,
  +Samples:int,?Arg:var,-Values:list).
mc_mh_sample_arg(:Query:atom,:Evidence:atom,
  +Samples:int,+Lag:int,?Arg:var,-Values:list).
mc_mh_sample_arg(:Query:atom,:Evidence:atom,
  +Samples:int,+Mix:int,+Lag:int,?Arg:var,-Values:list).
\end{verbatim}
that return the distribution of values for \verb|Arg| in \verb|Query| in \verb|Samples| of
\verb|Query| given that \verb|Evidence| is true. \verb|Mix| indicates the
number of mixing samples.
The predicate returns in \verb|Values| a list of couples \verb|L-N| where
\verb|L| is the list of values of \verb|Arg| for which \verb|Query|
succeeds in a world sampled at random where \verb|Evidence| is true and \verb|N|
is the number of samples returning that list of values.

An example of use of the above predicates is
\begin{verbatim}
?- mc_mh_sample_arg(eval(2,Y),eval(1,3),1000,1,Y,V).
\end{verbatim}
of \href{http://cplint.lamping.unife.it/example/inference/arithm.pl}{\texttt{arithm.pl}}.

Finally, you can compute expectations with 
\begin{verbatim}
mc_expectation(:Query:atom,+N:int,?Arg:var,-Exp:float).
\end{verbatim}
that computes the expected value of \verb|Arg| in \verb|Query| by
sampling.
It takes \verb|N| samples of \verb|Query| and sums up the value of \verb|Arg| for
each sample. The overall sum is divided by \verb|N| to give \verb|Exp|.

An example of use of the above predicate is
\begin{verbatim}
?- mc_expectation(eventually(elect,T),1000,T,E).
\end{verbatim}
of \href{http://cplint.lamping.unife.it/example/inference/pctl_slep.pl}{\texttt{pctl\_slep.pl}}
that returns in \verb|E| the expected value of \verb|T| by taking 1000 samples.

To compute conditional expectations, use
\begin{verbatim}
mc_mh_expectation(:Query:atom,:Evidence:atom,+N:int,
  +Lag:int,?Arg:var,-Exp:float).
mc_rejection_expectation(:Query:atom,:Evidence:atom,+N:int,
  ?Arg:var,-Exp:float).
\end{verbatim}
as in
\begin{verbatim}
?- mc_mh_expectation(eval(2,Y),eval(1,3),1000,1,Y,E).
\end{verbatim}
of \href{http://cplint.lamping.unife.it/example/inference/arithm.pl}{\texttt{arithm.pl}}
that computes the expectation of argument \verb|Y| of \verb|eval(2,Y)| given that 
\verb|eval(1,3)| is true by taking 1000 samples using Metropolis-Hastings MCMC.

The predicate
\begin{verbatim}
mc_mh_expectation(:Query:atom,:Evidence:atom,+N:int,+Mix:int,
  +Lag:int,?Arg:var,-Exp:float).
\end{verbatim}
allows for \verb|Mix| mixing samples.

\subsection{Conditional Queries on Continuous Variables}
\label{condqcont}

When you have continuous random variables, you may be interested in 
sampling arguments of goals representing continuous random variables.
In this way you can build a probability density of the sampled argument.
When you do not have evidence or you have evidence on atoms not depending
on continuous random variables, you can use the above predicates for sampling
arguments.

For example
\begin{verbatim}
?- mc_sample_arg(value(0,X),1000,X,L).
\end{verbatim}
from (\href{http://cplint.lamping.unife.it/example/inference/gauss_mean_est.pl}{\texttt{gauss\_mean\_est.pl}})) samples 1000 values for \verb|X| in
\verb|value(0,X)| and returns them in \verb|L|.

When you have evidence on ground atoms that have continuous values as 
arguments, you cannot use rejection sampling or Metropolis-Hastings,
as the probability of the evidence is 0. For example,
the probability of sampling a specific value from a Gaussian is 0. 
Continuous variables have probability densities instead of distributions as 
discrete variables.
In this case, you can use likelihood weighting or particle filtering \cite{fung1990weighing,koller2009probabilistic,Nitti2016} to obtain samples of 
continuous arguments of a goal.

For each sample to be taken, likelihood weighting
uses a meta-interpreter to find a sample where 
the goal is true, randomizing the choice of 
clauses when more than one resolves with the goal 
in order to obtain an unbiased sample.
This meta-interpreter is similar to the one used 
to generate the first sample in Metropolis-Hastings.

Then a different meta-interpreter is used to evaluate
the weight of the sample.
This meta-interpreter starts with the evidence as the query and a weight of 1. Each time the meta-interpreter encounters 
a probabilistic choice over a continuous variable, it first checks whether a
value has already been sampled.
If so, it computes the probability density of the sampled value and multiplies the weight by it. If the value has not been sampled, it takes a sample and records it, 
leaving the weight unchanged. 
In this way, each sample in the result has a weight that is 1 for the prior distribution and that may be different from the posterior distribution,
reflecting the influence of evidence.

In particle filtering, the evidence is a list of atoms. Each sample is weighted by the
likelihood of an element of the evidence and constitutes a particle. 
After weighting, particles are resampled and the next element of the evidence
is considered.

 The predicate 
\begin{verbatim}
mc_lw_sample(:Query:atom,:Evidence:atom,+Samples:int,-Prob:floar) is det
\end{verbatim}
samples \verb|Query|  a number of \verb|Samples| times given that \verb|Evidence|
(a conjunction of atoms is allowed here). is true.
The predicate returns in \verb|Prob| the probability that the query is true.
It performs likelihood weighting: each sample is weighted by the
likelihood of evidence in the sample.
For example
\begin{verbatim}
?- mc_lw_sample(nation(a),student_gpa(4.0),1000,PPost).
\end{verbatim}
from \href{http://cplint.lamping.unife.it/example/inference/indian_gpa.pl}{\texttt{indian\_gpa.pl}} samples 1000 the query
\verb|nation(a)| given that \verb|student_gpa(4.0)| has been observed.


 The predicate 
\begin{verbatim}
mc_lw_sample_arg(:Query:atom,:Evidence:atom,+N:int,?Arg:var,-ValList)
\end{verbatim}
returns in \verb|ValList| a list of couples \verb|V-W| where \verb|V| is a value of \verb|Arg| 
for which \verb|Query| succeeds and \verb|W| is the
weight computed by likelihood weighting
according to \verb|Evidence| (a conjunction of atoms is allowed here).
For example
\begin{verbatim}
?- mc_lw_sample_arg(value(0,X),(value(1,9),value(2,8)),100,X,L).
\end{verbatim}
from \href{http://cplint.lamping.unife.it/example/inference/gauss_mean_est.pl}{\texttt{gauss\_mean\_est.pl}} samples 100 values for \verb|X| in
\verb|value(0,X)| given that \verb|value(1,9)| and \verb|value(2,8)| have been observed.

The predicate
\begin{verbatim}
mc_particle_sample(:Query:atom,:Evidence:list,
  +Samples:int,-Prob:float)
\end{verbatim}
samples \verb|Query|  a number of \verb|Samples| times given that 
\verb|Evidence|
is true using particle filtering. \verb|Evidence| is a list of goals.
The predicate returns in \verb|Prob| the probability that the query is true.
For each goal of \verb|Evidence|, \verb|Samples| samples of \verb|Query| are taken
and weighted by the likelihood of the evidence goal.
Then particles are resampled and the next element of Evidence
is considered.

The predicate
\begin{verbatim}
mc_particle_sample_arg(:Query:atom,+Evidence:term,
  +Samples:int,?Arg:var,-Values:list) 
\end{verbatim}
samples argument \verb|Arg| of \verb|Query| using particle filtering 
given that 
\verb|Evidence|
is true. \verb|Evidence| is a list of goals and \verb|Query| can be either
a single goal or a list of goals.
When \verb|Query| is a single goal, the predicate returns in \verb|Values| a list of couples \verb|V-W| where
\verb|V| is a value of \verb|Arg| for which \verb|Query| succeeds in
a particle in the last set of particles and \verb|W| is the weight of the particle.
For each element of \verb|Evidence|, the particles are obtained by sampling \verb|Query|
in each current particle and weighting the particle by the likelihood of the evidence element.

When \verb|Query| is a list of goals,  \verb|Arg| is a list of variables, one for 
each query of \verb|Query| and \verb|Arg| and \verb|Query| must have the same length of \verb|Evidence|.
\verb|Values| is then list of the same length of \verb|Evidence| and each of its
elements is a list of couples \verb|V-W| where
\verb|V| is a value of the corresponding element of \verb|Arg| for which the corresponding element of
\verb|Query| succeeds in
a particle and \verb|W| is the weight of the particle.
For each element of \verb|Evidence|, the particles are obtained by sampling the corresponding element of \verb|Query|
in each current particle and weighting the particle by the likelihood of the evidence element.


For example
\begin{verbatim}
?-[O1,O2,O3,O4]=[-0.133, -1.183, -3.212, -4.586],
mc_particle_sample_arg([kf_fin(1,T1),kf_fin(2,T2),kf_fin(3,T3),kf_fin(4,T4)],
  [kf_o(1,O1),kf_o(2,O2),kf_o(3,O3),kf_o(4,O4)],100,[T1,T2,T3,T4],[F1,F2,F3,F4]).
\end{verbatim}
from \href{http://cplint.lamping.unife.it/example/inference/kalman_filter.pl}{\texttt{kalman\_filter.pl}} performs
particle filtering for a Kalman filter with four observations. For each observation, the value of the state 
at the same time point is sampled. The list of samples is returned in \verb|[F1,F2,F3,F4]|, with each element
the samples for the successive time points. 
